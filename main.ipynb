{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection\n"
      ],
      "metadata": {
        "id": "1taK5DL8Tg27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import praw\n",
        "import pandas as pd\n",
        "import re\n",
        "from time import sleep\n"
      ],
      "metadata": {
        "id": "eU8zkQX_ouqh"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "8_8392FkorAr"
      },
      "outputs": [],
      "source": [
        "# Forum Scraper (Greeklish)\n",
        "def scrape_forum():\n",
        "\n",
        "    \"\"\"Scrapes forum posts from insomnia.gr.\n",
        "\n",
        "    Returns:\n",
        "        A list of forum post texts.\n",
        "    \"\"\"\n",
        "\n",
        "    url = 'https://www.insomnia.gr/forums/'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    posts = soup.find_all('p', class_='ipsHide')  # Adjust class based on site\n",
        "    return [post.text for post in posts[:100]]\n",
        "\n",
        "# YouTube Comments (Greeklish)\n",
        "def scrape_youtube():\n",
        "    \"\"\"Scrapes comments from a YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        A list of comment texts.\n",
        "    \"\"\"\n",
        "    url = 'https://www.youtube.com/watch?v=_akH1Bns2B8'\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    comments = soup.find_all('yt-formatted-string', class_='style-scope ytd-comment-renderer')\n",
        "    return [comment.text for comment in comments[:100]]\n",
        "\n",
        "# Reddit Scraper\n",
        "\n",
        "def is_valid_greeklish(text):\n",
        "\n",
        "    \"\"\"Checks if a text is likely to be Greeklish.\n",
        "\n",
        "    Args:\n",
        "        text: The text to check.\n",
        "\n",
        "    Returns:\n",
        "        True if the text is likely to be Greeklish, False otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    if len(text) < 3 or text in [\"[deleted]\", \"[removed]\"]:\n",
        "        return False\n",
        "\n",
        "    # Reject Greek/Cyrillic scripts\n",
        "    if re.search(r'[α-ωά-ώΑ-Ω]', text) or re.search(r'[а-яА-Я]', text):\n",
        "        return False\n",
        "\n",
        "    # Reject excessive numbers/leet (e.g., \"k4n315\")\n",
        "    if sum(c.isdigit() for c in text) > len(text) * 0.2:\n",
        "        return False\n",
        "\n",
        "    # Key Greeklish words (customize as needed)\n",
        "    greeklish_words = {\n",
        "        \"kaneis\", \"einai\", \"thelw\", \"gia\", \"auto\", \"kai\", \"den\", \"ti\", \"mou\",\n",
        "        \"sou\", \"tora\", \"minymata\", \"ellinika\", \"greeklish\", \"vlepw\", \"kserw\"\n",
        "    }\n",
        "    words = set(re.findall(r'\\b\\w+\\b', text))\n",
        "    return len(words & greeklish_words) >= 2  # At least 2 Greeklish words\n",
        "\n",
        "\n",
        "def scrape_reddit():\n",
        "\n",
        "    \"\"\"Scrapes Reddit posts from the r/greece subreddit.\n",
        "\n",
        "    Returns:\n",
        "        A list of Reddit post titles.\n",
        "    \"\"\"\n",
        "\n",
        "    posts = []\n",
        "    reddit = praw.Reddit(client_id='XYqJYrsAQ1NjcH2po55CIA', client_secret='WJS-uobHelasoF3khZb4KLPnVq05Yg', user_agent='GreeklishScraper/0.0.1', check_for_async=False)\n",
        "    subreddit = reddit.subreddit(\"greece\")\n",
        "    for submission in subreddit.search(\"greeklish\", limit=400):\n",
        "      if is_valid_greeklish(submission.title):\n",
        "        posts.append({\"text\": submission.title, \"label\": \"greeklish\"})\n",
        "\n",
        "      if submission.comments:\n",
        "           submission.comments.replace_more(limit=0)\n",
        "           for comment in submission.comments.list():\n",
        "             if is_valid_greeklish(comment.body):\n",
        "                 posts.append({\"text\": comment.body, \"label\": \"greeklish\"})\n",
        "    return [submission.title for submission in subreddit.search(\"greeklish\", limit=400)]\n",
        "\n",
        "# (English)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    \"\"\"Cleans and preprocesses text data.\n",
        "\n",
        "    Args:\n",
        "        text: The text to clean.\n",
        "\n",
        "    Returns:\n",
        "        The cleaned text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Remove extra whitespace and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def scrape_reddit_sentences(subreddit_name=\"AskReddit\", min_sentences=150):\n",
        "    \"\"\"Scrapes sentences from Reddit posts and comments.\n",
        "\n",
        "    Args:\n",
        "        subreddit_name: The name of the subreddit to scrape.\n",
        "        min_sentences: The minimum number of sentences to scrape.\n",
        "\n",
        "    Returns:\n",
        "        A list of sentences.\n",
        "    \"\"\"\n",
        "    # Initialize Reddit API\n",
        "    reddit = praw.Reddit(\n",
        "        client_id=\"XYqJYrsAQ1NjcH2po55CIA\",\n",
        "        client_secret=\"WJS-uobHelasoF3khZb4KLPnVq05Yg\",\n",
        "        user_agent=\"sentence_scraper_v1\"\n",
        "    )\n",
        "\n",
        "    all_sentences = []\n",
        "    subreddit = reddit.subreddit(subreddit_name)\n",
        "\n",
        "    # Get top posts and comments\n",
        "    for submission in subreddit.top(limit=50):\n",
        "        submission.comments.replace_more(limit=0)\n",
        "        # Add submission title\n",
        "        title_sentences = nltk.sent_tokenize(clean_text(submission.title))\n",
        "        all_sentences.extend(title_sentences)\n",
        "\n",
        "        # Add comments\n",
        "        for comment in submission.comments.list():\n",
        "            if hasattr(comment, 'body'):\n",
        "                comment_sentences = nltk.sent_tokenize(clean_text(comment.body))\n",
        "                all_sentences.extend(comment_sentences)\n",
        "\n",
        "        if len(all_sentences) >= min_sentences:\n",
        "            break\n",
        "\n",
        "    return all_sentences[:min_sentences]\n",
        "\n",
        "def scrape_wikipedia_sentences(url, min_sentences=150):\n",
        "\n",
        "    \"\"\"Scrapes sentences from Wikipedia articles.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the Wikipedia article.\n",
        "        min_sentences: The minimum number of sentences to scrape.\n",
        "\n",
        "    Returns:\n",
        "        A list of sentences.\n",
        "    \"\"\"\n",
        "    # Set headers to mimic browser\n",
        "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Find content paragraphs (Wikipedia uses 'mw-paragraph' in content)\n",
        "    paragraphs = soup.find_all('p')\n",
        "\n",
        "    all_sentences = []\n",
        "    for para in paragraphs:\n",
        "        text = para.get_text()\n",
        "        # Remove citation numbers like [1], [2] etc.\n",
        "        text = re.sub(r'\\[\\d+\\]', '', text)\n",
        "        sentences = nltk.sent_tokenize(clean_text(text))\n",
        "        all_sentences.extend(sentences)\n",
        "\n",
        "    return all_sentences[:min_sentences] if len(all_sentences) > min_sentences else all_sentences\n",
        "\n",
        "\n",
        "\n",
        "# Combine data\n",
        "def collect_data():\n",
        "\n",
        "    \"\"\"Collects Greeklish and English data.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing two lists: Greeklish data and English data.\n",
        "    \"\"\"\n",
        "\n",
        "    greeklish = scrape_youtube() + scrape_forum() + scrape_reddit()\n",
        "    english = scrape_wikipedia_sentences(\"https://en.wikipedia.org/wiki/Artificial_intelligence\",200) + scrape_reddit_sentences(\"AskReddit\",200)\n",
        "    return greeklish, english\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to CSV\n",
        "greeklish_data, english_data = collect_data()\n",
        "# Check the length of the data and adjust labels accordingly\n",
        "greeklish_len = len(greeklish_data)\n",
        "english_len = len(english_data)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'text': greeklish_data + english_data,\n",
        "    'label': ['Greeklish'] * greeklish_len + ['English'] * english_len\n",
        "})\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooDeEtbdshAJ",
        "outputId": "8040fde6-c96c-438d-eb42-8786e09852f7"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(593, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('initial_dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "Y3h9n-Iowwvg"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "AEUOB-ngTu0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/initial_dataset.csv')\n",
        "\n",
        "\n",
        "def split_into_sentences(paragraph):\n",
        "    # Simple sentence splitting based on periods, exclamation, and question marks\n",
        "    sentences = [s.strip() for s in paragraph.replace('!', '.').replace('?', '.').split('.') if s.strip()]\n",
        "    return sentences\n",
        "\n",
        "# Create a new DataFrame with one sentence per row\n",
        "new_rows = []\n",
        "for index, row in df.iterrows():\n",
        "    sentences = split_into_sentences(row['text'])\n",
        "    for sentence in sentences:\n",
        "        new_row = row.copy()\n",
        "        new_row['text'] = sentence\n",
        "        new_rows.append(new_row)\n",
        "\n",
        "# Create new DataFrame\n",
        "new_df = pd.DataFrame(new_rows)\n",
        "\n",
        "# Reset index if needed\n",
        "new_df = new_df.reset_index(drop=True)\n",
        "\n",
        "# Save to new CSV file\n",
        "new_df.to_csv('output.csv', index=False)\n",
        "\n",
        "print(f\"Original DataFrame size: {len(df)} rows\")\n",
        "print(f\"New DataFrame size: {len(new_df)} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcB4wx0D9mns",
        "outputId": "7ffb17f2-bfa9-4d73-a0a1-4de3f8e2a77d"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original DataFrame size: 593 rows\n",
            "New DataFrame size: 674 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "DIzDXAZIJylU"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZyloS7aJ0ym",
        "outputId": "883832bb-cb38-40a5-81b0-731bb50926c4"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/final_dataset.csv')"
      ],
      "metadata": {
        "id": "bt3fstTXJ5OX"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the data\n",
        "print(\"Initial data preview:\")\n",
        "print(df.head())\n",
        "print(f\"Total sentences: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HK0xrmKJ1ng",
        "outputId": "bf883588-f353-48c7-9cd5-bf53d15d9df0"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial data preview:\n",
            "                                                                                                  text  \\\n",
            "0  den eixa ellinika sto kinito mou gia xronia kai akoma kai twra pou exw stelnw minymata se greekl...   \n",
            "1                8ymamai na einai 2003 kai na vlepw greeklish na xrisimopoiountai akomi kai sta forums   \n",
            "2                                                                         eixan ki afta tin plaka tous   \n",
            "3                                                                  episis, 8ym4741 k4n315 70 13375p34k   \n",
            "4                                                                                                   :D   \n",
            "\n",
            "       label  \n",
            "0  greeklish  \n",
            "1  greeklish  \n",
            "2  greeklish  \n",
            "3  greeklish  \n",
            "4  greeklish  \n",
            "Total sentences: 904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning and preprocessing function\n",
        "def preprocess_text(text):\n",
        "\n",
        "    \"\"\"Cleans and preprocesses a sentence.\n",
        "\n",
        "    Args:\n",
        "        text: The sentence to preprocess.\n",
        "\n",
        "    Returns:\n",
        "        The preprocessed sentence.\n",
        "    \"\"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters, numbers, and extra whitespace\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords (English stopwords; minimal impact on Greeklish)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    # Join tokens back into a sentence\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "x37wlYJuJ1kz"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "df['cleaned_sentence'] = df['text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "HGRpGGN0J1iD"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop empty rows after cleaning\n",
        "df = df[df['cleaned_sentence'] != ''].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "s4bZAuV6J1YA"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare final DataFrame (rename 'text' to 'sentence' as per convention)\n",
        "df_final = df[['cleaned_sentence', 'label']].rename(columns={'cleaned_sentence': 'sentence'})"
      ],
      "metadata": {
        "id": "M4rzWNAeJ1Vd"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify class distribution\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df_final['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vPcPpVKKFer",
        "outputId": "b137dae3-8f90-402c-858b-c2176ed3519b"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Class distribution:\n",
            "label\n",
            "greeklish    497\n",
            "English      388\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save preprocessed data\n",
        "df_final.to_csv('preprocessed_sentences.csv', index=False)\n",
        "print(\"\\nPreprocessed data saved as 'preprocessed_sentences.csv' and downloaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Ev8B-Z3RKFbu",
        "outputId": "0f8d56fa-7c85-4ffd-f1dc-64e3532a6081"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f4e7b9d7-3985-4987-a044-2e953ba00088\", \"preprocessed_sentences.csv\", 74606)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessed data saved as 'preprocessed_sentences.csv' and downloaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development"
      ],
      "metadata": {
        "id": "gH3ZO0cCT2hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features (X) and labels (y)\n",
        "X = df_final['sentence']\n",
        "y = df_final['label']"
      ],
      "metadata": {
        "id": "gpMu9uEFKFZJ"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "lf9GYpV5KZn3"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit features for efficiency\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "NGKANV09KamB"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression classifier\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "-o3sj6nWKaj2",
        "outputId": "7634405f-c3cd-42c1-ccb8-eac1a4bd7038"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test set\n",
        "y_pred = model.predict(X_test_tfidf)"
      ],
      "metadata": {
        "id": "wTUx5xW0KahN"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')"
      ],
      "metadata": {
        "id": "2kD4VtRxKaef"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NtUey-uKab-",
        "outputId": "afa3ff3f-b69f-40ff-94aa-cc45675d1926"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Performance:\n",
            "Accuracy: 0.9492\n",
            "Precision: 0.9544\n",
            "Recall: 0.9492\n",
            "F1-Score: 0.9493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model and vectorizer using joblib to the 'model' directory\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create a directory to store the model files\n",
        "os.makedirs('model', exist_ok=True)\n",
        "\n",
        "joblib.dump(model, 'model/greeklish_classifier.pkl')\n",
        "joblib.dump(vectorizer, 'model/tfidf_vectorizer.pkl')\n",
        "print(\"\\nModel and vectorizer saved to the 'model' directory.\")\n",
        "\n",
        "# Download model files\n",
        "!zip -r model.zip model  # Zip the 'model' directory\n",
        "from google.colab import files\n",
        "files.download('model.zip')\n",
        "print(\"Model files zipped and downloaded as 'model.zip'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "Lx_pKX5fMf1P",
        "outputId": "c2d227d0-c69a-482c-9f96-8c56e670b3cc"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model and vectorizer saved to the 'model' directory.\n",
            "  adding: model/ (stored 0%)\n",
            "  adding: model/greeklish_classifier.pkl (deflated 42%)\n",
            "  adding: model/tfidf_vectorizer.pkl (deflated 75%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_752ffb79-8c78-4512-8049-2106c714dacc\", \"model.zip\", 51007)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model files zipped and downloaded as 'model.zip'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = joblib.load(\"greeklish_classifier.pkl\")\n",
        "\n",
        "# Function to classify a sentence\n",
        "def predict_text(text):\n",
        "\n",
        "    \"\"\"Classifies a sentence as Greeklish or English.\n",
        "\n",
        "    Args:\n",
        "        text: The sentence to classify.\n",
        "\n",
        "    Returns:\n",
        "        The predicted label ('Greeklish' or 'English').\n",
        "    \"\"\"\n",
        "\n",
        "    processed_text = preprocess_text(text)\n",
        "    # Reshape the processed_text to a 2D array with one column\n",
        "    # The following line is changed\n",
        "    prediction = model.predict(vectorizer.transform([processed_text]))[0]\n",
        "    return prediction\n",
        "\n",
        "# Test examples\n",
        "print(predict_text(\"ti kaneis\"))  # Expected output: Greeklish\n",
        "print(predict_text(\"Hello, how are you?\"))  # Expected output: English"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khhujvFcMiSy",
        "outputId": "46b31c85-1fab-4ab1-9ffc-4c564886a6ba"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "greeklish\n",
            "English\n"
          ]
        }
      ]
    }
  ]
}